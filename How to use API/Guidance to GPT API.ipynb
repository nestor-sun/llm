{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c46900f",
   "metadata": {},
   "source": [
    "# How to Use GPT API via Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa630f42",
   "metadata": {},
   "source": [
    "## What is GPT?  \n",
    "OpenAI's GPT (generative pre-trained transformer) models have been trained to understand natural language and code. GPTs provide text outputs in response to their inputs. The inputs to GPTs are also referred to as \"prompts\". Designing a prompt is essentially how you “program” a GPT model, usually by providing instructions or some examples of how to successfully complete a task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805eba38",
   "metadata": {},
   "source": [
    "## What can it help?\n",
    "Using GPTs, you can build applications to:\n",
    "\n",
    "- Draft documents\n",
    "- Write computer code\n",
    "- Answer questions about a knowledge base\n",
    "- Analyze texts\n",
    "- Create conversational agents\n",
    "- Give software a natural language interface\n",
    "- Tutor in a range of subjects\n",
    "- Translate languages\n",
    "- Simulate characters for games\n",
    "...and much more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa0bba",
   "metadata": {},
   "source": [
    "## Why should you use GPT API instead of chatGPT web page?\n",
    "While using the chatGPT web page can provide a similar experience to the GPT API, there are several reasons why using the GPT API can be advantageous:\n",
    "\n",
    "- Flexibility: Integrating the GPT API in your own applications or platforms gives you more freedom and control over how the model interacts with your users. You can design personalized user experiences and tailor the model's responses according to your specific needs.\n",
    "\n",
    "- Scalability: The GPT API allows you to scale and handle larger traffic volumes easily. With the chatGPT web page, there may be limitations on the number of instances you can run simultaneously or the number of concurrent requests you can handle.\n",
    "\n",
    "- Automation: Using the GPT API, you can fully automate prompts and responses by making API calls directly from your code. This automation can be useful for building chatbots, customer support systems, content generation pipelines, and more.\n",
    "\n",
    "- Rich functionalities: The GPT API provides several options to enhance and customize the model's behavior. You can preprocess inputs, set temperature and max tokens, add system and user messages, instruct the model with explicit guidelines, and have greater control over the conversation flow.\n",
    "\n",
    "- Diversity in integration: Integrating the GPT API allows you to use the model's capabilities in platforms and environments that might not support the chatGPT web page. This includes mobile apps, browser extensions, server applications, command-line tools, and any other software that can make HTTP requests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320aba3",
   "metadata": {},
   "source": [
    "## Why should you choose it?\n",
    "In recent years, large language models (LLM) have been bursting. Every tech giant is building their own LLM. But here OpenAI\\`s GPT is still recommended among so many LLMs. Here are the reasons:\n",
    "- Performance: GPT models have achieved state-of-the-art results on a wide range of natural language processing (NLP) tasks due to their large scale and pre-training objectives.\n",
    "\n",
    "- Versatility: GPT models can be fine-tuned for a variety of NLP tasks such as text classification, summarization, question-answering, and more. This flexibility allows you to adapt the model to your specific use case.\n",
    "\n",
    "- Pre-training on diverse data: GPT models are trained on a vast amount of publicly available text from the internet. This exposure to a wide variety of topics and domains helps them understand and generate diverse types of content.\n",
    "\n",
    "- Continual Improvements: OpenAI invests in ongoing research and development to improve their language models. As a result, new versions of the GPT models are regularly released with enhancements to their capabilities.\n",
    "\n",
    "- Large community and support: OpenAI has a large and active user community, providing resources, documentation, and forums where you can seek help, share ideas, and collaborate with others using GPT models.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59a29248",
   "metadata": {},
   "source": [
    "## How can you get GPT API keys?\n",
    "To use OpenAI's GPT API, first you need to obtain the API key. Following three steps will show your how to get the API keys:\n",
    "1. Visit and sign up at https://platform.openai.com/. \n",
    "2. Log in, then at the top right corner, click account icon. Go to \"View API keys\".\n",
    "<center><img src=\"files/step2.png\" width=\"100\" height=\"200\"></center>\n",
    "3. Click \"generate new secret key\". Your API key will show. Save it.\n",
    "<center><img src=\"files/step3.png\" width=\"400\" height=\"400\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68150c02",
   "metadata": {},
   "source": [
    "## How do you deploy API with python?\n",
    "Let's assume now you have API keys. Next you need to delpoy the API with python.\n",
    "First, you need to install the specific python package offered by OpenAI. This step just needs one line code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ba5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install openai package. You can also do this in a terminal with code \"pip install openai\"\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a48d5",
   "metadata": {},
   "source": [
    "Now you need to let OPENAI know who you are and whether you are eligible to use their API. To do this, you need to set your API key with the following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b3a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "OPENAI_API_KEY = 'YourAPIKEY'\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2254f9d",
   "metadata": {},
   "source": [
    "Now let's try to ask your first question to GPT via your API. For example, you want to ask GPT \"Who are the best 10 player in NBA?\". You can send your question and get response with following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0970cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"best\" players in the NBA can be subjective based on individual opinions and can also change over time. However, as of October 2021, some widely regarded top players in the NBA include:\n",
      "\n",
      "1. LeBron James (Los Angeles Lakers)\n",
      "2. Kevin Durant (Brooklyn Nets)\n",
      "3. Giannis Antetokounmpo (Milwaukee Bucks)\n",
      "4. Stephen Curry (Golden State Warriors)\n",
      "5. Kawhi Leonard (LA Clippers)\n",
      "6. Luka Dončić (Dallas Mavericks)\n",
      "7. James Harden (Brooklyn Nets)\n",
      "8. Damian Lillard (Portland Trail Blazers)\n",
      "9. Joel Embiid (Philadelphia 76ers)\n",
      "10. Nikola Jokić (Denver Nuggets)\n",
      "\n",
      "It's important to note that this list might vary depending on personal preferences and different NBA seasons.\n"
     ]
    }
   ],
   "source": [
    "texts=\"Who are the best 10 player in NBA?\"\n",
    "message=[{\"role\": \"user\", \"content\": \n",
    "          texts}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "max_tokens=2000,\n",
    "temperature=1.2,\n",
    "messages = message)\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832b456",
   "metadata": {},
   "source": [
    "Now you get the response from GPT. Let's examine the codes above:\n",
    "- __texts__ are the prompts you send to GPT. In plain words, it is the question you ask GPT, the words you say to GPT. \n",
    "- __message__ contains the conversation history. By reading the \"message\", GPT knows who says what and it can react accordingly. The two keys here are __role__ and __content__ , showing who says what. There are three roles in GPT system, which are \"system\",\"user\", and \"assistant\". Since you want to use the GPT, when you send prompts, your role is \"user\". Note that __message__ is the history of conversation. If you want to talk with GPT as you have a conversation, you need to make sure __message__ contains all the prompts from you and responses from GPT. In coding language, you need to append all the prompts from you and responses from GPT in time order in the __message__ . If you do not this, GPT cannot remmember what you two have talked about. __The codes we are talking about now cannot achieve the conversation style. They are just one time Q&A__. But we will see how to make it like a conversation later.\n",
    "- __openai.ChatCompletion.create()__ is the core action in this code. It sends the prompt from users and fetches response from GPT. __model__ specifies which GPT model you want to use. For the models you can use, visit https://platform.openai.com/docs/models for detail. __max_tokens__ controls the length of response from GPT. The larger __max_tokens__ is, the longer the response from GPT could be, and of course, the longer GPT will take to generate the response. Fine the max tokens of different models here https://platform.openai.com/docs/models/gpt-4 and https://platform.openai.com/docs/models/gpt-3-5. __temperature__ is a parameter that controls the “creativity” or randomness of the text generated by GPT-3. A higher temperature (e.g., 0.7) results in more diverse and creative output, while a lower temperature (e.g., 0.2) makes the output more deterministic and focused. In practice, temperature affects the probability distribution over the possible tokens at each step of the generation process. A temperature of 0 would make the model completely deterministic, always choosing the most likely token. __messages__ takes the history of conversation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87520e53",
   "metadata": {},
   "source": [
    "## How to deploy GPT in a conversation manner?\n",
    "As mentioned, if you want to play with GPT as you two are having a conversation, you need to show the conversation history to GPT, letting it know who said what. This feature can be achieved by appending all previous prompts and responses to __messages__ . Following codes are example to show how to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f20330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChatGPT_conversation(conversation):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=conversation,\n",
    "        max_tokens=16000\n",
    "    )\n",
    "    # api_usage = response['usage']\n",
    "    # print('Total token consumed: {0}'.format(api_usage['total_tokens']))\n",
    "    # stop means complete\n",
    "    # print(response['choices'][0].finish_reason)\n",
    "    # print(response['choices'][0].index)\n",
    "    conversation.append({'role': response.choices[0].message.role, 'content': response.choices[0].message.content})\n",
    "    return conversation\n",
    "\n",
    "conversation = []\n",
    "conversation.append({'role': 'system', 'content': 'How may I help you?'})\n",
    "conversation = ChatGPT_conversation(conversation)\n",
    "print('{0}: {1}\\n'.format(conversation[-1]['role'].strip(), conversation[-1]['content'].strip()))\n",
    "\n",
    "while True:\n",
    "    prompt = input('User: ')\n",
    "    conversation.append({'role': 'user', 'content': prompt})\n",
    "    conversation = ChatGPT_conversation(conversation)\n",
    "    print('{0}: {1}\\n'.format(conversation[-1]['role'].strip(), conversation[-1]['content'].strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab454ac9",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://platform.openai.com/docs/models\n",
    "- https://platform.openai.com/docs/guides/gpt\n",
    "- https://learndataanalysis.org/getting-started-with-openai-gpt-gpt-3-5-model-api-in-python/\n",
    "- https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api-a-few-tips-and-tricks-on-controlling-the-creativity-deterministic-output-of-prompt-responses/172683"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openai]",
   "language": "python",
   "name": "conda-env-openai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
